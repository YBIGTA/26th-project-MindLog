import numpy as np
import cv2
import os
import requests
from deepface import DeepFace
from scipy.spatial.distance import cosine
from scipy.cluster.hierarchy import fcluster, linkage
from typing import Dict, List
import tempfile

class CompanionTagger:
    def __init__(self, face_database: dict = None):
        """ğŸ”¹ ì–¼êµ´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°›ìŒ"""
        self.face_database = face_database or {}

    def download_image(self, image_url: str):
        """ğŸ”¹ URL ì´ë¯¸ì§€ë¥¼ ë¡œì»¬ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            response = requests.get(image_url, timeout=5)
            response.raise_for_status()
            image_data = np.frombuffer(response.content, np.uint8)
            image = cv2.imdecode(image_data, cv2.IMREAD_COLOR)
            
            # âœ… ì´ë¯¸ì§€ ì„ì‹œ ì €ì¥ (DeepFaceëŠ” ë¡œì»¬ íŒŒì¼ í•„ìš”)
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".jpg")
            cv2.imwrite(temp_file.name, image)

            return temp_file.name  # âœ… ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë°˜í™˜
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {image_url}, ì˜¤ë¥˜: {e}")
            return None

    def get_face_embeddings(self, image_urls: List[str], confidence_threshold=0.9, min_face_size=30):
        """ğŸ”¹ URLì„ í†µí•´ ì–¼êµ´ ê²€ì¶œ ë° ì„ë² ë”© ì¶”ì¶œ"""
        face_data = []
        for image_url in image_urls:
            try:
                temp_image_path = self.download_image(image_url)
                if temp_image_path is None:
                    continue  # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê±´ë„ˆëœ€
                
                detected_faces = DeepFace.extract_faces(img_path=temp_image_path, detector_backend="mtcnn")
                filtered_faces = [
                    face for face in detected_faces
                    if face.get("confidence", 0) >= confidence_threshold
                    and face["face"].shape[0] > min_face_size
                ]

                if not filtered_faces:
                    print(f"âš ï¸ {image_url} â†’ ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨ (ì¸ë¬¼ íƒœê·¸ ì—†ìŒ)")
                    continue

                for face in filtered_faces:
                    face_array = np.array(face["face"] * 255, dtype=np.uint8)

                    try:
                        emb = DeepFace.represent(img_path=temp_image_path, model_name="Facenet", enforce_detection=False)
                        if emb:
                            face_embedding = np.array(emb[0]['embedding'])
                            face_data.append((image_url, face_embedding, face_array))
                    except Exception as e:
                        print(f"âš ï¸ ì–¼êµ´ ì„ë² ë”© ì‹¤íŒ¨: {e}")

                # âœ… ì²˜ë¦¬ ì™„ë£Œ í›„ ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.remove(temp_image_path)

            except Exception as e:
                print(f"âŒ ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨: {image_url}, ì˜¤ë¥˜: {e}")

        return face_data

    def cluster_faces_hierarchical(self, face_data, threshold=0.7):
        """ğŸ”¹ ë°°ì¹˜ ë‚´ ì–¼êµ´ í´ëŸ¬ìŠ¤í„°ë§"""
        embeddings = np.array([data[1] for data in face_data if data[1] is not None])

        if len(embeddings) < 2:
            return {data[0]: "person_1" for data in face_data}

        linkage_matrix = linkage(embeddings, method="ward")
        clusters = fcluster(linkage_matrix, threshold, criterion="distance")

        assigned_tags = {}
        for i, cluster_id in enumerate(clusters):
            assigned_tags[face_data[i][0]] = f"person_{cluster_id}"

        return assigned_tags

    def match_with_database(self, assigned_tags, face_data, threshold=0.7):
        """ğŸ”¹ ê¸°ì¡´ DBì™€ ë¹„êµí•˜ì—¬ ìµœì¢… ì¸ë¬¼ íƒœê¹…"""
        updated_tags = assigned_tags.copy()
        next_person_id = len(self.face_database) + 1

        for img_path, embedding, face_img in face_data:
            if embedding is None:
                continue  # ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨í•œ ê²½ìš° ì œì™¸

            best_match = None
            best_similarity = 0

            for person_id, data in self.face_database.items():
                for existing_embedding in data.get("embeddings", []):
                    similarity = 1 - cosine(embedding, existing_embedding)
                    if similarity >= threshold and similarity > best_similarity:
                        best_similarity = similarity
                        best_match = person_id

            if best_match:
                updated_tags[img_path] = best_match
                self.face_database[best_match]["embeddings"].append(embedding.tolist())  # âœ… Numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                self.face_database[best_match]["faces"].append(face_img.tolist())  # âœ… OpenCV ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                self.face_database[best_match]["image_paths"].append(img_path)
            else:
                new_person_tag = f"person_{next_person_id}"
                updated_tags[img_path] = new_person_tag
                self.face_database[new_person_tag] = {
                    "embeddings": [embedding.tolist()],  # âœ… JSON ë³€í™˜ ê°€ëŠ¥í•˜ë„ë¡ ë¦¬ìŠ¤íŠ¸ ë³€í™˜
                    "faces": [face_img.tolist()],  # âœ… JSON ë³€í™˜ ê°€ëŠ¥í•˜ë„ë¡ ë¦¬ìŠ¤íŠ¸ ë³€í™˜
                    "image_paths": [img_path],
                }
                next_person_id += 1

        return updated_tags

    def process_faces(self, image_urls: List[str], face_database: dict = None):
        """ğŸ”¹ ì¸ë¬¼ íƒœê¹… ì‹¤í–‰ í•¨ìˆ˜"""
        
        # ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
        self.face_database = face_database or {}

        face_data = self.get_face_embeddings(image_urls)
        batch_tags = self.cluster_faces_hierarchical(face_data)
        final_tags = self.match_with_database(batch_tags, face_data)

        return final_tags, self.face_database  # âœ… ì—…ë°ì´íŠ¸ëœ ì–¼êµ´ ë°ì´í„°ë² ì´ìŠ¤ ë°˜í™˜